{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CIFAR-10 Dataset: 171MB [01:39, 1.71MB/s]                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile('cifar-10-python.tar.gz'):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            'cifar-10-python.tar.gz',\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open('cifar-10-python.tar.gz') as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 4:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1003, 1: 963, 2: 1041, 3: 976, 4: 1004, 5: 1021, 6: 1004, 7: 981, 8: 1024, 9: 983}\n",
      "First 20 Labels: [0, 6, 0, 2, 7, 2, 1, 2, 4, 1, 5, 6, 6, 3, 1, 3, 5, 5, 8, 1]\n",
      "\n",
      "Example of Image 0:\n",
      "Image - Min Value: 34 Max Value: 203\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 0 Name: airplane\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1079af57b8>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 4\n",
    "sample_id = 0\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    \n",
    "    x = np.array(x)\n",
    "    return x/np.max(x)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "Hint: Don't reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(xs):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    output_size =10\n",
    "    \n",
    "    # Reinventing the wheel\n",
    "    n_xs = len(xs)\n",
    "    one_hot = np.zeros((n_xs, output_size), dtype=np.float32)\n",
    "    one_hot[range(n_xs),(xs)] = 1\n",
    "    \n",
    "    return one_hot\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    ">**Note:** If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages to build each layer, except the layers you build in the \"Convolutional and Max Pooling Layer\" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    ">However, if you would like to get the most out of this course, try to solve all the problems _without_ using anything from the TF Layers packages. You **can** still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the `conv2d` class, [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d), you would want to use the TF Neural Network version of `conv2d`, [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d). \n",
    "\n",
    "Let's begin!\n",
    "\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a bach of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    \n",
    "    return tf.placeholder(tf.float32, shape=(None, image_shape[0], image_shape[1], image_shape[2]), name='x')\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    \n",
    "    return tf.placeholder(tf.float32,(None, n_classes), name='y')\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    \n",
    "    return tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "**Note:** You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for **this** layer, but you can still use TensorFlow's [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) package. You may still use the shortcut option for all the **other** layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convolution\n",
    "    input_depth = int(x_tensor.shape[-1])\n",
    "    weight_size = (conv_ksize[0], conv_ksize[1], input_depth, conv_num_outputs)\n",
    "    conv_strides = (1, conv_strides[0], conv_strides[1], 1)\n",
    "    weights = tf.Variable(tf.truncated_normal(weight_size, dtype=tf.float32, stddev=0.1))\n",
    "    bias = tf.Variable(tf.zeros((conv_num_outputs,), dtype=tf.float32))\n",
    "    conv2d_tensor = tf.nn.conv2d(x_tensor, weights, conv_strides, 'SAME') + bias\n",
    "    relu_tensor = tf.nn.relu(conv2d_tensor)\n",
    "    \n",
    "    # Maxpooling\n",
    "    pool_ksize = (1, pool_ksize[0], pool_ksize[1], 1)\n",
    "    pool_strides = (1, pool_strides[0], pool_strides[1], 1)\n",
    "    max_tensor = tf.nn.max_pool(relu_tensor, pool_ksize, pool_strides, 'SAME')\n",
    "    \n",
    "    return max_tensor\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "\n",
    "    # Skipping the batch dimension\n",
    "    static_dimensions = x_tensor.shape[1:]\n",
    "    \n",
    "    flatten_image_size = 1\n",
    "    for dimension in static_dimensions:\n",
    "        flatten_image_size *= int(dimension)\n",
    "    \n",
    "    # Only using basic TensorFlow    \n",
    "    return tf.reshape(x_tensor, [-1, flatten_image_size])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, n_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    \n",
    "    n_inputs = int(x_tensor.shape[1])\n",
    "    weight_shape = (n_inputs, n_outputs)\n",
    "    weights = tf.Variable(tf.truncated_normal(weight_shape, stddev=0.1, dtype=tf.float32))\n",
    "    bias = tf.Variable(tf.zeros(n_outputs), dtype=tf.float32)\n",
    "    logits = tf.add(tf.matmul(x_tensor, weights), bias)\n",
    "    activation = tf.nn.relu(logits)\n",
    "    \n",
    "    return activation\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "**Note:** Activation, softmax, or cross entropy should **not** be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, n_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    n_inputs = int(x_tensor.shape[1])\n",
    "    weight_shape = (n_inputs, n_outputs)\n",
    "    weights = tf.Variable(tf.truncated_normal(weight_shape, stddev=0.1, dtype=tf.float32))\n",
    "    bias = tf.Variable(tf.zeros(n_outputs), dtype=tf.float32)\n",
    "    output = tf.add(tf.matmul(x_tensor, weights), bias)\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    \n",
    "    # Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    # Play around with different number of outputs, kernel size and stride\n",
    "    conv_stride = (1,1)\n",
    "    pool_size = (2,2)\n",
    "    pool_stride = pool_size\n",
    "    model = x\n",
    "    model = conv2d_maxpool(model, 64, (2,2), conv_stride, pool_size, pool_stride)\n",
    "    model = conv2d_maxpool(model, 64, (2,2), conv_stride, pool_size, pool_stride)\n",
    "    model = conv2d_maxpool(model, 64, (2,2), conv_stride, pool_size, pool_stride)\n",
    "    \n",
    "    \n",
    "    #  Apply a Flatten Layer    \n",
    "    model = flatten(model)\n",
    "\n",
    "    # Apply 1, 2, or 3 Fully Connected Layers\n",
    "    # Play around with different number of outputs\n",
    "    #model = fully_conn(model, 40)\n",
    "    #model = fully_conn(model, 20)\n",
    "    #model = fully_conn(model, 10)\n",
    "    \n",
    "    # Apply dropout\n",
    "    #model = tf.nn.dropout(model, keep_prob)\n",
    "    \n",
    "    # Apply an Output Layer\n",
    "    n_outputs = 10\n",
    "    model = output(model, n_outputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    \n",
    "    session.run(optimizer, feed_dict={keep_prob:keep_probability, x:feature_batch, y:label_batch})\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost_function, accuracy_function):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    \n",
    "    training_cost = session.run(cost_function, feed_dict={x:feature_batch, y:label_batch, keep_prob:1.0})\n",
    "    training_accuracy = session.run(accuracy_function, feed_dict={x:feature_batch, y:label_batch, keep_prob:1.0})\n",
    "    \n",
    "    validation_cost = session.run(cost_function, feed_dict={x:valid_features, y:valid_labels, keep_prob:1.0})\n",
    "    validation_accuracy = session.run(accuracy_function, feed_dict={x:valid_features, y:valid_labels, keep_prob:1.0})\n",
    "    \n",
    "    stats = 'Cost: {:6.3f} / {:6.3f}, \\t Accuracy: {:6.5f} / {:6.5f} \\t (Training/Validation)'\n",
    "    print(stats.format(training_cost, validation_cost, training_accuracy, validation_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 256\n",
    "keep_probability = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Cost:  2.059 /  1.983, \t Accuracy: 0.27500 / 0.29880 \t (Training/Validation)\n",
      "Epoch  2, CIFAR-10 Batch 1:  Cost:  1.873 /  1.767, \t Accuracy: 0.42500 / 0.37560 \t (Training/Validation)\n",
      "Epoch  3, CIFAR-10 Batch 1:  Cost:  1.696 /  1.649, \t Accuracy: 0.47500 / 0.42300 \t (Training/Validation)\n",
      "Epoch  4, CIFAR-10 Batch 1:  Cost:  1.579 /  1.558, \t Accuracy: 0.52500 / 0.45500 \t (Training/Validation)\n",
      "Epoch  5, CIFAR-10 Batch 1:  Cost:  1.459 /  1.502, \t Accuracy: 0.57500 / 0.47000 \t (Training/Validation)\n",
      "Epoch  6, CIFAR-10 Batch 1:  Cost:  1.350 /  1.456, \t Accuracy: 0.57500 / 0.48140 \t (Training/Validation)\n",
      "Epoch  7, CIFAR-10 Batch 1:  Cost:  1.261 /  1.415, \t Accuracy: 0.57500 / 0.50000 \t (Training/Validation)\n",
      "Epoch  8, CIFAR-10 Batch 1:  Cost:  1.190 /  1.372, \t Accuracy: 0.60000 / 0.51220 \t (Training/Validation)\n",
      "Epoch  9, CIFAR-10 Batch 1:  Cost:  1.125 /  1.340, \t Accuracy: 0.60000 / 0.52500 \t (Training/Validation)\n",
      "Epoch 10, CIFAR-10 Batch 1:  Cost:  1.053 /  1.321, \t Accuracy: 0.75000 / 0.53220 \t (Training/Validation)\n",
      "Epoch 11, CIFAR-10 Batch 1:  Cost:  0.984 /  1.308, \t Accuracy: 0.75000 / 0.53520 \t (Training/Validation)\n",
      "Epoch 12, CIFAR-10 Batch 1:  Cost:  0.930 /  1.299, \t Accuracy: 0.77500 / 0.53960 \t (Training/Validation)\n",
      "Epoch 13, CIFAR-10 Batch 1:  Cost:  0.873 /  1.288, \t Accuracy: 0.80000 / 0.54700 \t (Training/Validation)\n",
      "Epoch 14, CIFAR-10 Batch 1:  Cost:  0.826 /  1.275, \t Accuracy: 0.82500 / 0.55040 \t (Training/Validation)\n",
      "Epoch 15, CIFAR-10 Batch 1:  Cost:  0.781 /  1.265, \t Accuracy: 0.82500 / 0.55840 \t (Training/Validation)\n",
      "Epoch 16, CIFAR-10 Batch 1:  Cost:  0.738 /  1.259, \t Accuracy: 0.82500 / 0.56400 \t (Training/Validation)\n",
      "Epoch 17, CIFAR-10 Batch 1:  Cost:  0.705 /  1.250, \t Accuracy: 0.82500 / 0.56680 \t (Training/Validation)\n",
      "Epoch 18, CIFAR-10 Batch 1:  Cost:  0.669 /  1.244, \t Accuracy: 0.82500 / 0.56960 \t (Training/Validation)\n",
      "Epoch 19, CIFAR-10 Batch 1:  Cost:  0.632 /  1.239, \t Accuracy: 0.82500 / 0.57180 \t (Training/Validation)\n",
      "Epoch 20, CIFAR-10 Batch 1:  Cost:  0.606 /  1.237, \t Accuracy: 0.87500 / 0.57340 \t (Training/Validation)\n",
      "Epoch 21, CIFAR-10 Batch 1:  Cost:  0.573 /  1.240, \t Accuracy: 0.90000 / 0.57320 \t (Training/Validation)\n",
      "Epoch 22, CIFAR-10 Batch 1:  Cost:  0.543 /  1.232, \t Accuracy: 0.92500 / 0.57820 \t (Training/Validation)\n",
      "Epoch 23, CIFAR-10 Batch 1:  Cost:  0.509 /  1.225, \t Accuracy: 0.92500 / 0.57880 \t (Training/Validation)\n",
      "Epoch 24, CIFAR-10 Batch 1:  Cost:  0.478 /  1.219, \t Accuracy: 0.92500 / 0.58180 \t (Training/Validation)\n",
      "Epoch 25, CIFAR-10 Batch 1:  Cost:  0.450 /  1.220, \t Accuracy: 0.95000 / 0.58540 \t (Training/Validation)\n",
      "Epoch 26, CIFAR-10 Batch 1:  Cost:  0.424 /  1.224, \t Accuracy: 0.95000 / 0.58560 \t (Training/Validation)\n",
      "Epoch 27, CIFAR-10 Batch 1:  Cost:  0.404 /  1.227, \t Accuracy: 0.95000 / 0.58740 \t (Training/Validation)\n",
      "Epoch 28, CIFAR-10 Batch 1:  Cost:  0.380 /  1.234, \t Accuracy: 0.95000 / 0.58380 \t (Training/Validation)\n",
      "Epoch 29, CIFAR-10 Batch 1:  Cost:  0.357 /  1.230, \t Accuracy: 0.95000 / 0.58940 \t (Training/Validation)\n",
      "Epoch 30, CIFAR-10 Batch 1:  Cost:  0.342 /  1.205, \t Accuracy: 0.95000 / 0.59420 \t (Training/Validation)\n",
      "Epoch 31, CIFAR-10 Batch 1:  Cost:  0.338 /  1.211, \t Accuracy: 0.95000 / 0.59280 \t (Training/Validation)\n",
      "Epoch 32, CIFAR-10 Batch 1:  Cost:  0.314 /  1.206, \t Accuracy: 0.95000 / 0.59620 \t (Training/Validation)\n",
      "Epoch 33, CIFAR-10 Batch 1:  Cost:  0.291 /  1.207, \t Accuracy: 0.97500 / 0.60020 \t (Training/Validation)\n",
      "Epoch 34, CIFAR-10 Batch 1:  Cost:  0.274 /  1.211, \t Accuracy: 0.97500 / 0.60060 \t (Training/Validation)\n",
      "Epoch 35, CIFAR-10 Batch 1:  Cost:  0.258 /  1.215, \t Accuracy: 0.97500 / 0.60040 \t (Training/Validation)\n",
      "Epoch 36, CIFAR-10 Batch 1:  Cost:  0.244 /  1.220, \t Accuracy: 0.97500 / 0.59860 \t (Training/Validation)\n",
      "Epoch 37, CIFAR-10 Batch 1:  Cost:  0.231 /  1.227, \t Accuracy: 0.97500 / 0.59800 \t (Training/Validation)\n",
      "Epoch 38, CIFAR-10 Batch 1:  Cost:  0.217 /  1.230, \t Accuracy: 0.97500 / 0.59940 \t (Training/Validation)\n",
      "Epoch 39, CIFAR-10 Batch 1:  Cost:  0.206 /  1.235, \t Accuracy: 0.97500 / 0.59840 \t (Training/Validation)\n",
      "Epoch 40, CIFAR-10 Batch 1:  Cost:  0.196 /  1.240, \t Accuracy: 0.97500 / 0.59940 \t (Training/Validation)\n",
      "Epoch 41, CIFAR-10 Batch 1:  Cost:  0.186 /  1.244, \t Accuracy: 0.97500 / 0.60100 \t (Training/Validation)\n",
      "Epoch 42, CIFAR-10 Batch 1:  Cost:  0.178 /  1.248, \t Accuracy: 1.00000 / 0.60200 \t (Training/Validation)\n",
      "Epoch 43, CIFAR-10 Batch 1:  Cost:  0.170 /  1.253, \t Accuracy: 1.00000 / 0.60260 \t (Training/Validation)\n",
      "Epoch 44, CIFAR-10 Batch 1:  Cost:  0.161 /  1.257, \t Accuracy: 1.00000 / 0.60040 \t (Training/Validation)\n",
      "Epoch 45, CIFAR-10 Batch 1:  Cost:  0.146 /  1.256, \t Accuracy: 1.00000 / 0.60260 \t (Training/Validation)\n",
      "Epoch 46, CIFAR-10 Batch 1:  Cost:  0.136 /  1.266, \t Accuracy: 1.00000 / 0.60260 \t (Training/Validation)\n",
      "Epoch 47, CIFAR-10 Batch 1:  Cost:  0.139 /  1.293, \t Accuracy: 1.00000 / 0.59780 \t (Training/Validation)\n",
      "Epoch 48, CIFAR-10 Batch 1:  Cost:  0.135 /  1.278, \t Accuracy: 1.00000 / 0.60000 \t (Training/Validation)\n",
      "Epoch 49, CIFAR-10 Batch 1:  Cost:  0.127 /  1.270, \t Accuracy: 1.00000 / 0.60240 \t (Training/Validation)\n",
      "Epoch 50, CIFAR-10 Batch 1:  Cost:  0.122 /  1.278, \t Accuracy: 1.00000 / 0.60140 \t (Training/Validation)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Cost:  2.112 /  1.985, \t Accuracy: 0.17500 / 0.30540 \t (Training/Validation)\n",
      "Epoch  1, CIFAR-10 Batch 2:  Cost:  1.809 /  1.764, \t Accuracy: 0.37500 / 0.37620 \t (Training/Validation)\n",
      "Epoch  1, CIFAR-10 Batch 3:  Cost:  1.423 /  1.643, \t Accuracy: 0.47500 / 0.42120 \t (Training/Validation)\n",
      "Epoch  1, CIFAR-10 Batch 4:  Cost:  1.575 /  1.534, \t Accuracy: 0.42500 / 0.45200 \t (Training/Validation)\n",
      "Epoch  1, CIFAR-10 Batch 5:  Cost:  1.467 /  1.475, \t Accuracy: 0.50000 / 0.47360 \t (Training/Validation)\n",
      "Epoch  2, CIFAR-10 Batch 1:  Cost:  1.627 /  1.444, \t Accuracy: 0.47500 / 0.48840 \t (Training/Validation)\n",
      "Epoch  2, CIFAR-10 Batch 2:  Cost:  1.291 /  1.400, \t Accuracy: 0.57500 / 0.49460 \t (Training/Validation)\n",
      "Epoch  2, CIFAR-10 Batch 3:  Cost:  1.101 /  1.406, \t Accuracy: 0.65000 / 0.49920 \t (Training/Validation)\n",
      "Epoch  2, CIFAR-10 Batch 4:  Cost:  1.277 /  1.345, \t Accuracy: 0.55000 / 0.52340 \t (Training/Validation)\n",
      "Epoch  2, CIFAR-10 Batch 5:  Cost:  1.247 /  1.338, \t Accuracy: 0.57500 / 0.52620 \t (Training/Validation)\n",
      "Epoch  3, CIFAR-10 Batch 1:  Cost:  1.429 /  1.299, \t Accuracy: 0.57500 / 0.54360 \t (Training/Validation)\n",
      "Epoch  3, CIFAR-10 Batch 2:  Cost:  1.125 /  1.269, \t Accuracy: 0.52500 / 0.55220 \t (Training/Validation)\n",
      "Epoch  3, CIFAR-10 Batch 3:  Cost:  0.942 /  1.268, \t Accuracy: 0.70000 / 0.54880 \t (Training/Validation)\n",
      "Epoch  3, CIFAR-10 Batch 4:  Cost:  1.077 /  1.267, \t Accuracy: 0.70000 / 0.55020 \t (Training/Validation)\n",
      "Epoch  3, CIFAR-10 Batch 5:  Cost:  1.161 /  1.260, \t Accuracy: 0.60000 / 0.56160 \t (Training/Validation)\n",
      "Epoch  4, CIFAR-10 Batch 1:  Cost:  1.295 /  1.214, \t Accuracy: 0.65000 / 0.57420 \t (Training/Validation)\n",
      "Epoch  4, CIFAR-10 Batch 2:  Cost:  1.024 /  1.195, \t Accuracy: 0.60000 / 0.58400 \t (Training/Validation)\n",
      "Epoch  4, CIFAR-10 Batch 3:  Cost:  0.832 /  1.202, \t Accuracy: 0.72500 / 0.57740 \t (Training/Validation)\n",
      "Epoch  4, CIFAR-10 Batch 4:  Cost:  0.958 /  1.186, \t Accuracy: 0.67500 / 0.58140 \t (Training/Validation)\n",
      "Epoch  4, CIFAR-10 Batch 5:  Cost:  1.065 /  1.192, \t Accuracy: 0.60000 / 0.58640 \t (Training/Validation)\n",
      "Epoch  5, CIFAR-10 Batch 1:  Cost:  1.208 /  1.156, \t Accuracy: 0.67500 / 0.59840 \t (Training/Validation)\n",
      "Epoch  5, CIFAR-10 Batch 2:  Cost:  0.900 /  1.168, \t Accuracy: 0.60000 / 0.58640 \t (Training/Validation)\n",
      "Epoch  5, CIFAR-10 Batch 3:  Cost:  0.734 /  1.131, \t Accuracy: 0.77500 / 0.59660 \t (Training/Validation)\n",
      "Epoch  5, CIFAR-10 Batch 4:  Cost:  0.872 /  1.120, \t Accuracy: 0.67500 / 0.60900 \t (Training/Validation)\n",
      "Epoch  5, CIFAR-10 Batch 5:  Cost:  0.977 /  1.148, \t Accuracy: 0.65000 / 0.59920 \t (Training/Validation)\n",
      "Epoch  6, CIFAR-10 Batch 1:  Cost:  1.120 /  1.112, \t Accuracy: 0.67500 / 0.61320 \t (Training/Validation)\n",
      "Epoch  6, CIFAR-10 Batch 2:  Cost:  0.810 /  1.153, \t Accuracy: 0.67500 / 0.59520 \t (Training/Validation)\n",
      "Epoch  6, CIFAR-10 Batch 3:  Cost:  0.644 /  1.085, \t Accuracy: 0.80000 / 0.61680 \t (Training/Validation)\n",
      "Epoch  6, CIFAR-10 Batch 4:  Cost:  0.811 /  1.069, \t Accuracy: 0.72500 / 0.62380 \t (Training/Validation)\n",
      "Epoch  6, CIFAR-10 Batch 5:  Cost:  0.889 /  1.089, \t Accuracy: 0.70000 / 0.61660 \t (Training/Validation)\n",
      "Epoch  7, CIFAR-10 Batch 1:  Cost:  1.021 /  1.061, \t Accuracy: 0.70000 / 0.63080 \t (Training/Validation)\n",
      "Epoch  7, CIFAR-10 Batch 2:  Cost:  0.745 /  1.108, \t Accuracy: 0.75000 / 0.61460 \t (Training/Validation)\n",
      "Epoch  7, CIFAR-10 Batch 3:  Cost:  0.582 /  1.058, \t Accuracy: 0.82500 / 0.63000 \t (Training/Validation)\n",
      "Epoch  7, CIFAR-10 Batch 4:  Cost:  0.760 /  1.036, \t Accuracy: 0.77500 / 0.63660 \t (Training/Validation)\n",
      "Epoch  7, CIFAR-10 Batch 5:  Cost:  0.813 /  1.055, \t Accuracy: 0.72500 / 0.62900 \t (Training/Validation)\n",
      "Epoch  8, CIFAR-10 Batch 1:  Cost:  0.937 /  1.027, \t Accuracy: 0.67500 / 0.64700 \t (Training/Validation)\n",
      "Epoch  8, CIFAR-10 Batch 2:  Cost:  0.684 /  1.074, \t Accuracy: 0.80000 / 0.62480 \t (Training/Validation)\n",
      "Epoch  8, CIFAR-10 Batch 3:  Cost:  0.539 /  1.034, \t Accuracy: 0.87500 / 0.64260 \t (Training/Validation)\n",
      "Epoch  8, CIFAR-10 Batch 4:  Cost:  0.704 /  1.011, \t Accuracy: 0.77500 / 0.64340 \t (Training/Validation)\n",
      "Epoch  8, CIFAR-10 Batch 5:  Cost:  0.742 /  1.017, \t Accuracy: 0.77500 / 0.64400 \t (Training/Validation)\n",
      "Epoch  9, CIFAR-10 Batch 1:  Cost:  0.864 /  1.001, \t Accuracy: 0.67500 / 0.65420 \t (Training/Validation)\n",
      "Epoch  9, CIFAR-10 Batch 2:  Cost:  0.623 /  1.045, \t Accuracy: 0.80000 / 0.63840 \t (Training/Validation)\n",
      "Epoch  9, CIFAR-10 Batch 3:  Cost:  0.507 /  1.009, \t Accuracy: 0.87500 / 0.64920 \t (Training/Validation)\n",
      "Epoch  9, CIFAR-10 Batch 4:  Cost:  0.649 /  0.987, \t Accuracy: 0.80000 / 0.65180 \t (Training/Validation)\n",
      "Epoch  9, CIFAR-10 Batch 5:  Cost:  0.682 /  0.989, \t Accuracy: 0.80000 / 0.65280 \t (Training/Validation)\n",
      "Epoch 10, CIFAR-10 Batch 1:  Cost:  0.792 /  0.978, \t Accuracy: 0.70000 / 0.65980 \t (Training/Validation)\n",
      "Epoch 10, CIFAR-10 Batch 2:  Cost:  0.577 /  1.020, \t Accuracy: 0.85000 / 0.64240 \t (Training/Validation)\n",
      "Epoch 10, CIFAR-10 Batch 3:  Cost:  0.476 /  0.984, \t Accuracy: 0.90000 / 0.65680 \t (Training/Validation)\n",
      "Epoch 10, CIFAR-10 Batch 4:  Cost:  0.602 /  0.968, \t Accuracy: 0.87500 / 0.66200 \t (Training/Validation)\n",
      "Epoch 10, CIFAR-10 Batch 5:  Cost:  0.636 /  0.974, \t Accuracy: 0.82500 / 0.65700 \t (Training/Validation)\n",
      "Epoch 11, CIFAR-10 Batch 1:  Cost:  0.733 /  0.964, \t Accuracy: 0.75000 / 0.66160 \t (Training/Validation)\n",
      "Epoch 11, CIFAR-10 Batch 2:  Cost:  0.532 /  1.001, \t Accuracy: 0.87500 / 0.65120 \t (Training/Validation)\n",
      "Epoch 11, CIFAR-10 Batch 3:  Cost:  0.452 /  0.965, \t Accuracy: 0.90000 / 0.66520 \t (Training/Validation)\n",
      "Epoch 11, CIFAR-10 Batch 4:  Cost:  0.561 /  0.950, \t Accuracy: 0.90000 / 0.66920 \t (Training/Validation)\n",
      "Epoch 11, CIFAR-10 Batch 5:  Cost:  0.589 /  0.963, \t Accuracy: 0.87500 / 0.66140 \t (Training/Validation)\n",
      "Epoch 12, CIFAR-10 Batch 1:  Cost:  0.686 /  0.949, \t Accuracy: 0.77500 / 0.66580 \t (Training/Validation)\n",
      "Epoch 12, CIFAR-10 Batch 2:  Cost:  0.496 /  0.985, \t Accuracy: 0.87500 / 0.65880 \t (Training/Validation)\n",
      "Epoch 12, CIFAR-10 Batch 3:  Cost:  0.429 /  0.946, \t Accuracy: 0.87500 / 0.67480 \t (Training/Validation)\n",
      "Epoch 12, CIFAR-10 Batch 4:  Cost:  0.527 /  0.936, \t Accuracy: 0.90000 / 0.67540 \t (Training/Validation)\n",
      "Epoch 12, CIFAR-10 Batch 5:  Cost:  0.551 /  0.949, \t Accuracy: 0.92500 / 0.66760 \t (Training/Validation)\n",
      "Epoch 13, CIFAR-10 Batch 1:  Cost:  0.640 /  0.937, \t Accuracy: 0.77500 / 0.67060 \t (Training/Validation)\n",
      "Epoch 13, CIFAR-10 Batch 2:  Cost:  0.462 /  0.969, \t Accuracy: 0.90000 / 0.66800 \t (Training/Validation)\n",
      "Epoch 13, CIFAR-10 Batch 3:  Cost:  0.409 /  0.930, \t Accuracy: 0.90000 / 0.68300 \t (Training/Validation)\n",
      "Epoch 13, CIFAR-10 Batch 4:  Cost:  0.486 /  0.922, \t Accuracy: 0.90000 / 0.68080 \t (Training/Validation)\n",
      "Epoch 13, CIFAR-10 Batch 5:  Cost:  0.523 /  0.940, \t Accuracy: 0.92500 / 0.67060 \t (Training/Validation)\n",
      "Epoch 14, CIFAR-10 Batch 1:  Cost:  0.598 /  0.925, \t Accuracy: 0.82500 / 0.67280 \t (Training/Validation)\n",
      "Epoch 14, CIFAR-10 Batch 2:  Cost:  0.432 /  0.954, \t Accuracy: 0.90000 / 0.67720 \t (Training/Validation)\n",
      "Epoch 14, CIFAR-10 Batch 3:  Cost:  0.394 /  0.913, \t Accuracy: 0.90000 / 0.69020 \t (Training/Validation)\n",
      "Epoch 14, CIFAR-10 Batch 4:  Cost:  0.451 /  0.910, \t Accuracy: 0.90000 / 0.68740 \t (Training/Validation)\n",
      "Epoch 14, CIFAR-10 Batch 5:  Cost:  0.501 /  0.933, \t Accuracy: 0.92500 / 0.67780 \t (Training/Validation)\n",
      "Epoch 15, CIFAR-10 Batch 1:  Cost:  0.573 /  0.919, \t Accuracy: 0.85000 / 0.68020 \t (Training/Validation)\n",
      "Epoch 15, CIFAR-10 Batch 2:  Cost:  0.403 /  0.937, \t Accuracy: 0.90000 / 0.68400 \t (Training/Validation)\n",
      "Epoch 15, CIFAR-10 Batch 3:  Cost:  0.380 /  0.902, \t Accuracy: 0.92500 / 0.69080 \t (Training/Validation)\n",
      "Epoch 15, CIFAR-10 Batch 4:  Cost:  0.423 /  0.899, \t Accuracy: 0.90000 / 0.69340 \t (Training/Validation)\n",
      "Epoch 15, CIFAR-10 Batch 5:  Cost:  0.483 /  0.925, \t Accuracy: 0.92500 / 0.68300 \t (Training/Validation)\n",
      "Epoch 16, CIFAR-10 Batch 1:  Cost:  0.546 /  0.914, \t Accuracy: 0.85000 / 0.68400 \t (Training/Validation)\n",
      "Epoch 16, CIFAR-10 Batch 2:  Cost:  0.383 /  0.920, \t Accuracy: 0.90000 / 0.68960 \t (Training/Validation)\n",
      "Epoch 16, CIFAR-10 Batch 3:  Cost:  0.363 /  0.890, \t Accuracy: 0.92500 / 0.69780 \t (Training/Validation)\n",
      "Epoch 16, CIFAR-10 Batch 4:  Cost:  0.400 /  0.889, \t Accuracy: 0.90000 / 0.69560 \t (Training/Validation)\n",
      "Epoch 16, CIFAR-10 Batch 5:  Cost:  0.465 /  0.922, \t Accuracy: 0.92500 / 0.68640 \t (Training/Validation)\n",
      "Epoch 17, CIFAR-10 Batch 1:  Cost:  0.519 /  0.906, \t Accuracy: 0.85000 / 0.68740 \t (Training/Validation)\n",
      "Epoch 17, CIFAR-10 Batch 2:  Cost:  0.364 /  0.905, \t Accuracy: 0.95000 / 0.69580 \t (Training/Validation)\n",
      "Epoch 17, CIFAR-10 Batch 3:  Cost:  0.346 /  0.881, \t Accuracy: 0.92500 / 0.70260 \t (Training/Validation)\n",
      "Epoch 17, CIFAR-10 Batch 4:  Cost:  0.373 /  0.880, \t Accuracy: 0.90000 / 0.70020 \t (Training/Validation)\n",
      "Epoch 17, CIFAR-10 Batch 5:  Cost:  0.444 /  0.919, \t Accuracy: 0.92500 / 0.68660 \t (Training/Validation)\n",
      "Epoch 18, CIFAR-10 Batch 1:  Cost:  0.496 /  0.896, \t Accuracy: 0.85000 / 0.69440 \t (Training/Validation)\n",
      "Epoch 18, CIFAR-10 Batch 2:  Cost:  0.343 /  0.896, \t Accuracy: 0.95000 / 0.69700 \t (Training/Validation)\n",
      "Epoch 18, CIFAR-10 Batch 3:  Cost:  0.327 /  0.872, \t Accuracy: 0.92500 / 0.70460 \t (Training/Validation)\n",
      "Epoch 18, CIFAR-10 Batch 4:  Cost:  0.354 /  0.873, \t Accuracy: 0.90000 / 0.70300 \t (Training/Validation)\n",
      "Epoch 18, CIFAR-10 Batch 5:  Cost:  0.427 /  0.911, \t Accuracy: 0.92500 / 0.69080 \t (Training/Validation)\n",
      "Epoch 19, CIFAR-10 Batch 1:  Cost:  0.476 /  0.890, \t Accuracy: 0.85000 / 0.69560 \t (Training/Validation)\n",
      "Epoch 19, CIFAR-10 Batch 2:  Cost:  0.320 /  0.887, \t Accuracy: 0.95000 / 0.69960 \t (Training/Validation)\n",
      "Epoch 19, CIFAR-10 Batch 3:  Cost:  0.310 /  0.866, \t Accuracy: 0.92500 / 0.70600 \t (Training/Validation)\n",
      "Epoch 19, CIFAR-10 Batch 4:  Cost:  0.332 /  0.864, \t Accuracy: 0.92500 / 0.70680 \t (Training/Validation)\n",
      "Epoch 19, CIFAR-10 Batch 5:  Cost:  0.407 /  0.904, \t Accuracy: 0.92500 / 0.69480 \t (Training/Validation)\n",
      "Epoch 20, CIFAR-10 Batch 1:  Cost:  0.453 /  0.883, \t Accuracy: 0.85000 / 0.69780 \t (Training/Validation)\n",
      "Epoch 20, CIFAR-10 Batch 2:  Cost:  0.304 /  0.880, \t Accuracy: 0.97500 / 0.70240 \t (Training/Validation)\n",
      "Epoch 20, CIFAR-10 Batch 3:  Cost:  0.297 /  0.863, \t Accuracy: 0.92500 / 0.70880 \t (Training/Validation)\n",
      "Epoch 20, CIFAR-10 Batch 4:  Cost:  0.316 /  0.860, \t Accuracy: 0.95000 / 0.70720 \t (Training/Validation)\n",
      "Epoch 20, CIFAR-10 Batch 5:  Cost:  0.393 /  0.904, \t Accuracy: 0.92500 / 0.69280 \t (Training/Validation)\n",
      "Epoch 21, CIFAR-10 Batch 1:  Cost:  0.437 /  0.875, \t Accuracy: 0.87500 / 0.69980 \t (Training/Validation)\n",
      "Epoch 21, CIFAR-10 Batch 2:  Cost:  0.286 /  0.875, \t Accuracy: 0.97500 / 0.70240 \t (Training/Validation)\n",
      "Epoch 21, CIFAR-10 Batch 3:  Cost:  0.282 /  0.856, \t Accuracy: 0.92500 / 0.71300 \t (Training/Validation)\n",
      "Epoch 21, CIFAR-10 Batch 4:  Cost:  0.300 /  0.855, \t Accuracy: 0.95000 / 0.70960 \t (Training/Validation)\n",
      "Epoch 21, CIFAR-10 Batch 5:  Cost:  0.374 /  0.896, \t Accuracy: 0.92500 / 0.69600 \t (Training/Validation)\n",
      "Epoch 22, CIFAR-10 Batch 1:  Cost:  0.419 /  0.869, \t Accuracy: 0.90000 / 0.70420 \t (Training/Validation)\n",
      "Epoch 22, CIFAR-10 Batch 2:  Cost:  0.274 /  0.871, \t Accuracy: 0.97500 / 0.70580 \t (Training/Validation)\n",
      "Epoch 22, CIFAR-10 Batch 3:  Cost:  0.265 /  0.850, \t Accuracy: 0.92500 / 0.71520 \t (Training/Validation)\n",
      "Epoch 22, CIFAR-10 Batch 4:  Cost:  0.286 /  0.850, \t Accuracy: 0.95000 / 0.71180 \t (Training/Validation)\n",
      "Epoch 22, CIFAR-10 Batch 5:  Cost:  0.355 /  0.890, \t Accuracy: 0.92500 / 0.70100 \t (Training/Validation)\n",
      "Epoch 23, CIFAR-10 Batch 1:  Cost:  0.397 /  0.861, \t Accuracy: 0.90000 / 0.70640 \t (Training/Validation)\n",
      "Epoch 23, CIFAR-10 Batch 2:  Cost:  0.260 /  0.868, \t Accuracy: 0.97500 / 0.70720 \t (Training/Validation)\n",
      "Epoch 23, CIFAR-10 Batch 3:  Cost:  0.247 /  0.845, \t Accuracy: 0.92500 / 0.71520 \t (Training/Validation)\n",
      "Epoch 23, CIFAR-10 Batch 4:  Cost:  0.271 /  0.845, \t Accuracy: 0.95000 / 0.71340 \t (Training/Validation)\n",
      "Epoch 23, CIFAR-10 Batch 5:  Cost:  0.341 /  0.889, \t Accuracy: 0.92500 / 0.69820 \t (Training/Validation)\n",
      "Epoch 24, CIFAR-10 Batch 1:  Cost:  0.378 /  0.859, \t Accuracy: 0.90000 / 0.70940 \t (Training/Validation)\n",
      "Epoch 24, CIFAR-10 Batch 2:  Cost:  0.248 /  0.867, \t Accuracy: 0.97500 / 0.70760 \t (Training/Validation)\n",
      "Epoch 24, CIFAR-10 Batch 3:  Cost:  0.233 /  0.840, \t Accuracy: 0.95000 / 0.71760 \t (Training/Validation)\n",
      "Epoch 24, CIFAR-10 Batch 4:  Cost:  0.254 /  0.841, \t Accuracy: 1.00000 / 0.71420 \t (Training/Validation)\n",
      "Epoch 24, CIFAR-10 Batch 5:  Cost:  0.320 /  0.883, \t Accuracy: 0.95000 / 0.70060 \t (Training/Validation)\n",
      "Epoch 25, CIFAR-10 Batch 1:  Cost:  0.358 /  0.855, \t Accuracy: 0.92500 / 0.71040 \t (Training/Validation)\n",
      "Epoch 25, CIFAR-10 Batch 2:  Cost:  0.238 /  0.864, \t Accuracy: 0.97500 / 0.70980 \t (Training/Validation)\n",
      "Epoch 25, CIFAR-10 Batch 3:  Cost:  0.217 /  0.840, \t Accuracy: 0.95000 / 0.71580 \t (Training/Validation)\n",
      "Epoch 25, CIFAR-10 Batch 4:  Cost:  0.241 /  0.836, \t Accuracy: 1.00000 / 0.71540 \t (Training/Validation)\n",
      "Epoch 25, CIFAR-10 Batch 5:  Cost:  0.303 /  0.881, \t Accuracy: 0.95000 / 0.70160 \t (Training/Validation)\n",
      "Epoch 26, CIFAR-10 Batch 1:  Cost:  0.341 /  0.854, \t Accuracy: 0.95000 / 0.71120 \t (Training/Validation)\n",
      "Epoch 26, CIFAR-10 Batch 2:  Cost:  0.230 /  0.864, \t Accuracy: 0.97500 / 0.71020 \t (Training/Validation)\n",
      "Epoch 26, CIFAR-10 Batch 3:  Cost:  0.206 /  0.838, \t Accuracy: 0.95000 / 0.71640 \t (Training/Validation)\n",
      "Epoch 26, CIFAR-10 Batch 4:  Cost:  0.233 /  0.832, \t Accuracy: 1.00000 / 0.71600 \t (Training/Validation)\n",
      "Epoch 26, CIFAR-10 Batch 5:  Cost:  0.288 /  0.877, \t Accuracy: 0.97500 / 0.70040 \t (Training/Validation)\n",
      "Epoch 27, CIFAR-10 Batch 1:  Cost:  0.331 /  0.851, \t Accuracy: 0.97500 / 0.71300 \t (Training/Validation)\n",
      "Epoch 27, CIFAR-10 Batch 2:  Cost:  0.218 /  0.862, \t Accuracy: 0.97500 / 0.71140 \t (Training/Validation)\n",
      "Epoch 27, CIFAR-10 Batch 3:  Cost:  0.195 /  0.835, \t Accuracy: 0.95000 / 0.71800 \t (Training/Validation)\n",
      "Epoch 27, CIFAR-10 Batch 4:  Cost:  0.224 /  0.829, \t Accuracy: 1.00000 / 0.71700 \t (Training/Validation)\n",
      "Epoch 27, CIFAR-10 Batch 5:  Cost:  0.276 /  0.878, \t Accuracy: 0.97500 / 0.70040 \t (Training/Validation)\n",
      "Epoch 28, CIFAR-10 Batch 1:  Cost:  0.314 /  0.850, \t Accuracy: 0.97500 / 0.71380 \t (Training/Validation)\n",
      "Epoch 28, CIFAR-10 Batch 2:  Cost:  0.213 /  0.862, \t Accuracy: 0.97500 / 0.71400 \t (Training/Validation)\n",
      "Epoch 28, CIFAR-10 Batch 3:  Cost:  0.186 /  0.833, \t Accuracy: 0.97500 / 0.71960 \t (Training/Validation)\n",
      "Epoch 28, CIFAR-10 Batch 4:  Cost:  0.212 /  0.827, \t Accuracy: 1.00000 / 0.72000 \t (Training/Validation)\n",
      "Epoch 28, CIFAR-10 Batch 5:  Cost:  0.260 /  0.874, \t Accuracy: 0.97500 / 0.70340 \t (Training/Validation)\n",
      "Epoch 29, CIFAR-10 Batch 1:  Cost:  0.301 /  0.850, \t Accuracy: 0.97500 / 0.71400 \t (Training/Validation)\n",
      "Epoch 29, CIFAR-10 Batch 2:  Cost:  0.204 /  0.862, \t Accuracy: 0.97500 / 0.71560 \t (Training/Validation)\n",
      "Epoch 29, CIFAR-10 Batch 3:  Cost:  0.175 /  0.834, \t Accuracy: 0.97500 / 0.72200 \t (Training/Validation)\n",
      "Epoch 29, CIFAR-10 Batch 4:  Cost:  0.204 /  0.826, \t Accuracy: 1.00000 / 0.72140 \t (Training/Validation)\n",
      "Epoch 29, CIFAR-10 Batch 5:  Cost:  0.250 /  0.874, \t Accuracy: 1.00000 / 0.70440 \t (Training/Validation)\n",
      "Epoch 30, CIFAR-10 Batch 1:  Cost:  0.283 /  0.851, \t Accuracy: 0.97500 / 0.71500 \t (Training/Validation)\n",
      "Epoch 30, CIFAR-10 Batch 2:  Cost:  0.197 /  0.864, \t Accuracy: 0.97500 / 0.71700 \t (Training/Validation)\n",
      "Epoch 30, CIFAR-10 Batch 3:  Cost:  0.167 /  0.834, \t Accuracy: 0.97500 / 0.71940 \t (Training/Validation)\n",
      "Epoch 30, CIFAR-10 Batch 4:  Cost:  0.196 /  0.828, \t Accuracy: 1.00000 / 0.72240 \t (Training/Validation)\n",
      "Epoch 30, CIFAR-10 Batch 5:  Cost:  0.237 /  0.868, \t Accuracy: 1.00000 / 0.70580 \t (Training/Validation)\n",
      "Epoch 31, CIFAR-10 Batch 1:  Cost:  0.267 /  0.851, \t Accuracy: 1.00000 / 0.71620 \t (Training/Validation)\n",
      "Epoch 31, CIFAR-10 Batch 2:  Cost:  0.192 /  0.867, \t Accuracy: 0.97500 / 0.71480 \t (Training/Validation)\n",
      "Epoch 31, CIFAR-10 Batch 3:  Cost:  0.160 /  0.836, \t Accuracy: 1.00000 / 0.71900 \t (Training/Validation)\n",
      "Epoch 31, CIFAR-10 Batch 4:  Cost:  0.190 /  0.827, \t Accuracy: 1.00000 / 0.72280 \t (Training/Validation)\n",
      "Epoch 31, CIFAR-10 Batch 5:  Cost:  0.223 /  0.861, \t Accuracy: 1.00000 / 0.70820 \t (Training/Validation)\n",
      "Epoch 32, CIFAR-10 Batch 1:  Cost:  0.253 /  0.853, \t Accuracy: 1.00000 / 0.71440 \t (Training/Validation)\n",
      "Epoch 32, CIFAR-10 Batch 2:  Cost:  0.184 /  0.872, \t Accuracy: 0.97500 / 0.71460 \t (Training/Validation)\n",
      "Epoch 32, CIFAR-10 Batch 3:  Cost:  0.153 /  0.842, \t Accuracy: 1.00000 / 0.71800 \t (Training/Validation)\n",
      "Epoch 32, CIFAR-10 Batch 4:  Cost:  0.186 /  0.830, \t Accuracy: 1.00000 / 0.72280 \t (Training/Validation)\n",
      "Epoch 32, CIFAR-10 Batch 5:  Cost:  0.214 /  0.857, \t Accuracy: 1.00000 / 0.71080 \t (Training/Validation)\n",
      "Epoch 33, CIFAR-10 Batch 1:  Cost:  0.242 /  0.856, \t Accuracy: 1.00000 / 0.71480 \t (Training/Validation)\n",
      "Epoch 33, CIFAR-10 Batch 2:  Cost:  0.178 /  0.872, \t Accuracy: 0.97500 / 0.71620 \t (Training/Validation)\n",
      "Epoch 33, CIFAR-10 Batch 3:  Cost:  0.148 /  0.841, \t Accuracy: 1.00000 / 0.71860 \t (Training/Validation)\n",
      "Epoch 33, CIFAR-10 Batch 4:  Cost:  0.181 /  0.830, \t Accuracy: 1.00000 / 0.72420 \t (Training/Validation)\n",
      "Epoch 33, CIFAR-10 Batch 5:  Cost:  0.202 /  0.851, \t Accuracy: 1.00000 / 0.71480 \t (Training/Validation)\n",
      "Epoch 34, CIFAR-10 Batch 1:  Cost:  0.230 /  0.861, \t Accuracy: 1.00000 / 0.71500 \t (Training/Validation)\n",
      "Epoch 34, CIFAR-10 Batch 2:  Cost:  0.175 /  0.871, \t Accuracy: 0.97500 / 0.71880 \t (Training/Validation)\n",
      "Epoch 34, CIFAR-10 Batch 3:  Cost:  0.139 /  0.843, \t Accuracy: 1.00000 / 0.71900 \t (Training/Validation)\n",
      "Epoch 34, CIFAR-10 Batch 4:  Cost:  0.177 /  0.830, \t Accuracy: 1.00000 / 0.72600 \t (Training/Validation)\n",
      "Epoch 34, CIFAR-10 Batch 5:  Cost:  0.198 /  0.849, \t Accuracy: 1.00000 / 0.71440 \t (Training/Validation)\n",
      "Epoch 35, CIFAR-10 Batch 1:  Cost:  0.219 /  0.863, \t Accuracy: 1.00000 / 0.71620 \t (Training/Validation)\n",
      "Epoch 35, CIFAR-10 Batch 2:  Cost:  0.166 /  0.871, \t Accuracy: 0.97500 / 0.71740 \t (Training/Validation)\n",
      "Epoch 35, CIFAR-10 Batch 3:  Cost:  0.131 /  0.844, \t Accuracy: 1.00000 / 0.72020 \t (Training/Validation)\n",
      "Epoch 35, CIFAR-10 Batch 4:  Cost:  0.170 /  0.831, \t Accuracy: 1.00000 / 0.72640 \t (Training/Validation)\n",
      "Epoch 35, CIFAR-10 Batch 5:  Cost:  0.189 /  0.850, \t Accuracy: 1.00000 / 0.71700 \t (Training/Validation)\n",
      "Epoch 36, CIFAR-10 Batch 1:  Cost:  0.210 /  0.866, \t Accuracy: 1.00000 / 0.71680 \t (Training/Validation)\n",
      "Epoch 36, CIFAR-10 Batch 2:  Cost:  0.161 /  0.874, \t Accuracy: 0.97500 / 0.72000 \t (Training/Validation)\n",
      "Epoch 36, CIFAR-10 Batch 3:  Cost:  0.127 /  0.848, \t Accuracy: 1.00000 / 0.72080 \t (Training/Validation)\n",
      "Epoch 36, CIFAR-10 Batch 4:  Cost:  0.166 /  0.834, \t Accuracy: 1.00000 / 0.72400 \t (Training/Validation)\n",
      "Epoch 36, CIFAR-10 Batch 5:  Cost:  0.184 /  0.853, \t Accuracy: 1.00000 / 0.72000 \t (Training/Validation)\n",
      "Epoch 37, CIFAR-10 Batch 1:  Cost:  0.208 /  0.880, \t Accuracy: 1.00000 / 0.71240 \t (Training/Validation)\n",
      "Epoch 37, CIFAR-10 Batch 2:  Cost:  0.158 /  0.879, \t Accuracy: 0.97500 / 0.71900 \t (Training/Validation)\n",
      "Epoch 37, CIFAR-10 Batch 3:  Cost:  0.124 /  0.854, \t Accuracy: 1.00000 / 0.72100 \t (Training/Validation)\n",
      "Epoch 37, CIFAR-10 Batch 4:  Cost:  0.163 /  0.837, \t Accuracy: 1.00000 / 0.72200 \t (Training/Validation)\n",
      "Epoch 37, CIFAR-10 Batch 5:  Cost:  0.182 /  0.854, \t Accuracy: 1.00000 / 0.71840 \t (Training/Validation)\n",
      "Epoch 38, CIFAR-10 Batch 1:  Cost:  0.203 /  0.893, \t Accuracy: 1.00000 / 0.71020 \t (Training/Validation)\n",
      "Epoch 38, CIFAR-10 Batch 2:  Cost:  0.156 /  0.879, \t Accuracy: 0.97500 / 0.71940 \t (Training/Validation)\n",
      "Epoch 38, CIFAR-10 Batch 3:  Cost:  0.122 /  0.857, \t Accuracy: 1.00000 / 0.72100 \t (Training/Validation)\n",
      "Epoch 38, CIFAR-10 Batch 4:  Cost:  0.158 /  0.841, \t Accuracy: 1.00000 / 0.72160 \t (Training/Validation)\n",
      "Epoch 38, CIFAR-10 Batch 5:  Cost:  0.176 /  0.854, \t Accuracy: 1.00000 / 0.72080 \t (Training/Validation)\n",
      "Epoch 39, CIFAR-10 Batch 1:  Cost:  0.199 /  0.908, \t Accuracy: 1.00000 / 0.70740 \t (Training/Validation)\n",
      "Epoch 39, CIFAR-10 Batch 2:  Cost:  0.154 /  0.885, \t Accuracy: 0.97500 / 0.72000 \t (Training/Validation)\n",
      "Epoch 39, CIFAR-10 Batch 3:  Cost:  0.124 /  0.868, \t Accuracy: 0.97500 / 0.72020 \t (Training/Validation)\n",
      "Epoch 39, CIFAR-10 Batch 4:  Cost:  0.156 /  0.844, \t Accuracy: 1.00000 / 0.72060 \t (Training/Validation)\n",
      "Epoch 39, CIFAR-10 Batch 5:  Cost:  0.170 /  0.856, \t Accuracy: 1.00000 / 0.72180 \t (Training/Validation)\n",
      "Epoch 40, CIFAR-10 Batch 1:  Cost:  0.198 /  0.917, \t Accuracy: 1.00000 / 0.70580 \t (Training/Validation)\n",
      "Epoch 40, CIFAR-10 Batch 2:  Cost:  0.151 /  0.894, \t Accuracy: 0.97500 / 0.71800 \t (Training/Validation)\n",
      "Epoch 40, CIFAR-10 Batch 3:  Cost:  0.117 /  0.867, \t Accuracy: 0.97500 / 0.72000 \t (Training/Validation)\n",
      "Epoch 40, CIFAR-10 Batch 4:  Cost:  0.153 /  0.846, \t Accuracy: 1.00000 / 0.71900 \t (Training/Validation)\n",
      "Epoch 40, CIFAR-10 Batch 5:  Cost:  0.162 /  0.861, \t Accuracy: 1.00000 / 0.72060 \t (Training/Validation)\n",
      "Epoch 41, CIFAR-10 Batch 1:  Cost:  0.201 /  0.919, \t Accuracy: 1.00000 / 0.70400 \t (Training/Validation)\n",
      "Epoch 41, CIFAR-10 Batch 2:  Cost:  0.150 /  0.904, \t Accuracy: 1.00000 / 0.71540 \t (Training/Validation)\n",
      "Epoch 41, CIFAR-10 Batch 3:  Cost:  0.110 /  0.863, \t Accuracy: 0.97500 / 0.72140 \t (Training/Validation)\n",
      "Epoch 41, CIFAR-10 Batch 4:  Cost:  0.147 /  0.842, \t Accuracy: 1.00000 / 0.72220 \t (Training/Validation)\n",
      "Epoch 41, CIFAR-10 Batch 5:  Cost:  0.160 /  0.871, \t Accuracy: 1.00000 / 0.72120 \t (Training/Validation)\n",
      "Epoch 42, CIFAR-10 Batch 1:  Cost:  0.188 /  0.901, \t Accuracy: 1.00000 / 0.70920 \t (Training/Validation)\n",
      "Epoch 42, CIFAR-10 Batch 2:  Cost:  0.150 /  0.897, \t Accuracy: 1.00000 / 0.71560 \t (Training/Validation)\n",
      "Epoch 42, CIFAR-10 Batch 3:  Cost:  0.104 /  0.854, \t Accuracy: 1.00000 / 0.72500 \t (Training/Validation)\n",
      "Epoch 42, CIFAR-10 Batch 4:  Cost:  0.140 /  0.837, \t Accuracy: 1.00000 / 0.72580 \t (Training/Validation)\n",
      "Epoch 42, CIFAR-10 Batch 5:  Cost:  0.157 /  0.879, \t Accuracy: 1.00000 / 0.72140 \t (Training/Validation)\n",
      "Epoch 43, CIFAR-10 Batch 1:  Cost:  0.179 /  0.883, \t Accuracy: 1.00000 / 0.71580 \t (Training/Validation)\n",
      "Epoch 43, CIFAR-10 Batch 2:  Cost:  0.148 /  0.891, \t Accuracy: 1.00000 / 0.71580 \t (Training/Validation)\n",
      "Epoch 43, CIFAR-10 Batch 3:  Cost:  0.098 /  0.862, \t Accuracy: 1.00000 / 0.72220 \t (Training/Validation)\n",
      "Epoch 43, CIFAR-10 Batch 4:  Cost:  0.136 /  0.834, \t Accuracy: 1.00000 / 0.73060 \t (Training/Validation)\n",
      "Epoch 43, CIFAR-10 Batch 5:  Cost:  0.153 /  0.878, \t Accuracy: 1.00000 / 0.72200 \t (Training/Validation)\n",
      "Epoch 44, CIFAR-10 Batch 1:  Cost:  0.171 /  0.883, \t Accuracy: 1.00000 / 0.71480 \t (Training/Validation)\n",
      "Epoch 44, CIFAR-10 Batch 2:  Cost:  0.140 /  0.889, \t Accuracy: 1.00000 / 0.71560 \t (Training/Validation)\n",
      "Epoch 44, CIFAR-10 Batch 3:  Cost:  0.095 /  0.863, \t Accuracy: 1.00000 / 0.72580 \t (Training/Validation)\n",
      "Epoch 44, CIFAR-10 Batch 4:  Cost:  0.129 /  0.835, \t Accuracy: 1.00000 / 0.72880 \t (Training/Validation)\n",
      "Epoch 44, CIFAR-10 Batch 5:  Cost:  0.148 /  0.868, \t Accuracy: 1.00000 / 0.72240 \t (Training/Validation)\n",
      "Epoch 45, CIFAR-10 Batch 1:  Cost:  0.159 /  0.882, \t Accuracy: 1.00000 / 0.71440 \t (Training/Validation)\n",
      "Epoch 45, CIFAR-10 Batch 2:  Cost:  0.138 /  0.887, \t Accuracy: 0.97500 / 0.71780 \t (Training/Validation)\n",
      "Epoch 45, CIFAR-10 Batch 3:  Cost:  0.087 /  0.868, \t Accuracy: 1.00000 / 0.72460 \t (Training/Validation)\n",
      "Epoch 45, CIFAR-10 Batch 4:  Cost:  0.127 /  0.836, \t Accuracy: 1.00000 / 0.73140 \t (Training/Validation)\n",
      "Epoch 45, CIFAR-10 Batch 5:  Cost:  0.147 /  0.862, \t Accuracy: 1.00000 / 0.72560 \t (Training/Validation)\n",
      "Epoch 46, CIFAR-10 Batch 1:  Cost:  0.155 /  0.883, \t Accuracy: 1.00000 / 0.71680 \t (Training/Validation)\n",
      "Epoch 46, CIFAR-10 Batch 2:  Cost:  0.134 /  0.886, \t Accuracy: 0.97500 / 0.71900 \t (Training/Validation)\n",
      "Epoch 46, CIFAR-10 Batch 3:  Cost:  0.084 /  0.869, \t Accuracy: 1.00000 / 0.72340 \t (Training/Validation)\n",
      "Epoch 46, CIFAR-10 Batch 4:  Cost:  0.125 /  0.841, \t Accuracy: 1.00000 / 0.72840 \t (Training/Validation)\n",
      "Epoch 46, CIFAR-10 Batch 5:  Cost:  0.149 /  0.860, \t Accuracy: 1.00000 / 0.72560 \t (Training/Validation)\n",
      "Epoch 47, CIFAR-10 Batch 1:  Cost:  0.151 /  0.883, \t Accuracy: 1.00000 / 0.71500 \t (Training/Validation)\n",
      "Epoch 47, CIFAR-10 Batch 2:  Cost:  0.131 /  0.883, \t Accuracy: 0.97500 / 0.71860 \t (Training/Validation)\n",
      "Epoch 47, CIFAR-10 Batch 3:  Cost:  0.079 /  0.870, \t Accuracy: 1.00000 / 0.72240 \t (Training/Validation)\n",
      "Epoch 47, CIFAR-10 Batch 4:  Cost:  0.126 /  0.847, \t Accuracy: 1.00000 / 0.72720 \t (Training/Validation)\n",
      "Epoch 47, CIFAR-10 Batch 5:  Cost:  0.151 /  0.864, \t Accuracy: 0.97500 / 0.72460 \t (Training/Validation)\n",
      "Epoch 48, CIFAR-10 Batch 1:  Cost:  0.144 /  0.882, \t Accuracy: 1.00000 / 0.71720 \t (Training/Validation)\n",
      "Epoch 48, CIFAR-10 Batch 2:  Cost:  0.131 /  0.888, \t Accuracy: 0.97500 / 0.71940 \t (Training/Validation)\n",
      "Epoch 48, CIFAR-10 Batch 3:  Cost:  0.077 /  0.865, \t Accuracy: 1.00000 / 0.72360 \t (Training/Validation)\n",
      "Epoch 48, CIFAR-10 Batch 4:  Cost:  0.126 /  0.858, \t Accuracy: 1.00000 / 0.72500 \t (Training/Validation)\n",
      "Epoch 48, CIFAR-10 Batch 5:  Cost:  0.148 /  0.868, \t Accuracy: 1.00000 / 0.72400 \t (Training/Validation)\n",
      "Epoch 49, CIFAR-10 Batch 1:  Cost:  0.141 /  0.885, \t Accuracy: 1.00000 / 0.72020 \t (Training/Validation)\n",
      "Epoch 49, CIFAR-10 Batch 2:  Cost:  0.130 /  0.895, \t Accuracy: 1.00000 / 0.71880 \t (Training/Validation)\n",
      "Epoch 49, CIFAR-10 Batch 3:  Cost:  0.072 /  0.862, \t Accuracy: 1.00000 / 0.72400 \t (Training/Validation)\n",
      "Epoch 49, CIFAR-10 Batch 4:  Cost:  0.131 /  0.877, \t Accuracy: 1.00000 / 0.72260 \t (Training/Validation)\n",
      "Epoch 49, CIFAR-10 Batch 5:  Cost:  0.144 /  0.872, \t Accuracy: 1.00000 / 0.72300 \t (Training/Validation)\n",
      "Epoch 50, CIFAR-10 Batch 1:  Cost:  0.135 /  0.887, \t Accuracy: 1.00000 / 0.72080 \t (Training/Validation)\n",
      "Epoch 50, CIFAR-10 Batch 2:  Cost:  0.128 /  0.901, \t Accuracy: 1.00000 / 0.71580 \t (Training/Validation)\n",
      "Epoch 50, CIFAR-10 Batch 3:  Cost:  0.070 /  0.858, \t Accuracy: 1.00000 / 0.72780 \t (Training/Validation)\n",
      "Epoch 50, CIFAR-10 Batch 4:  Cost:  0.135 /  0.896, \t Accuracy: 1.00000 / 0.71760 \t (Training/Validation)\n",
      "Epoch 50, CIFAR-10 Batch 5:  Cost:  0.140 /  0.873, \t Accuracy: 1.00000 / 0.72520 \t (Training/Validation)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.71826171875\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmZmZmSUOjs3MzMzMkv8PBNARdAE+bQ0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f10df0c3ef0>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_training.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for train_feature_batch, train_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: train_feature_batch, loaded_y: train_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Why 50-70% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 70%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
